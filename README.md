# PRAGATI - Personalized Rapid Adaptive Growth And Training Intelligence

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![React](https://img.shields.io/badge/react-18.3+-61dafb.svg)](https://reactjs.org/)

> **AI-Powered Educational Platform for Teacher Training**  
> Transforming static training manuals into personalized, micro-learning modules for teachers in resource-constrained environments.

## ğŸ¯ Problem Statement

Current teacher training systems face critical challenges:
- **Static Content**: One-size-fits-all manuals updated every 3-4 months
- **Low Relevance**: Generic training doesn't address specific classroom challenges
- **Poor Accessibility**: Limited vernacular language support for rural teachers
- **No Feedback Loop**: Zero tracking of implementation effectiveness

## ğŸ’¡ Our Solution

PRAGATI leverages **RAG (Retrieval Augmented Generation)** to create:
- âœ… **Personalized Micro-Learning**: 15-minute modules tailored to specific challenges
- âœ… **Vernacular Support**: Multi-language translation (Hindi, Bengali, Tamil, Telugu, Marathi)
- âœ… **Offline-First PWA**: Works on 2G/3G connectivity
- âœ… **Implementation Tracking**: Feedback loop to measure real-world impact

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    subgraph Frontend
        A[React PWA] --> B[Service Worker]
        B --> C[Offline Cache]
    end
    
    subgraph Backend
        D[FastAPI] --> E[RAG Service]
        E --> F[Vector DB<br/>ChromaDB]
        E --> G[LLM<br/>Ministral-3B]
        E --> H[Embeddings<br/>MiniLM]
    end
    
    A -->|API Calls| D
    
    style A fill:#4f46e5
    style D fill:#10b981
    style G fill:#f59e0b
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Node.js 20+
- Ollama (for local LLM)

### Installation (Local Development)

#### Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env

# Install and start Ollama (https://ollama.ai)
ollama pull ministral:3b

# Run the backend
python main.py
```

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

### Docker Deployment (Experimental)

> **Note:** Docker support is currently experimental and has not been fully tested.

```bash
docker-compose up --build
```

## ğŸ“š Usage

### Generate Micro-Learning Module

1. Open the frontend at `http://localhost:5173`
2. Enter a classroom challenge (e.g., "Students in my class have varying learning speeds")
3. The AI will generate a personalized 15-minute micro-learning module.

```bash
# API Equivalent
curl -X POST http://localhost:8000/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "challenge": "Students in my class have varying learning speeds",
    "target_duration": 15,
    "difficulty_level": "intermediate"
  }'
```

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework**: FastAPI
- **LLM**: Ollama (Ministral-3B)
- **Embeddings**: sentence-transformers (all-MiniLM-L6-v2)
- **Vector DB**: ChromaDB
- **Document Processing**: PyPDF2, pdfplumber

### Frontend
- **Framework**: React 18 + Vite
- **PWA**: vite-plugin-pwa + Workbox
- **Styling**: Tailwind CSS
- **Animations**: Framer Motion
- **Icons**: Lucide React
- **HTTP Client**: Axios

### DevOps
- **Containerization**: Docker (Experimental)

## ğŸ“ Project Structure

```
pragati/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                 # API routes
â”‚   â”œâ”€â”€ models/              # Pydantic schemas
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ translation_service.py
â”‚   â”‚   â””â”€â”€ micro_learning_service.py
â”‚   â”œâ”€â”€ utils/               # Utilities
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ services/        # API client
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ“ Key Features

### 1. RAG Pipeline
- **Document Ingestion**: Automatic PDF parsing and chunking
- **Semantic Search**: Vector similarity search using embeddings
- **Context-Aware Generation**: LLM generates content from retrieved chunks

### 2. Micro-Learning Engine
- **Challenge-Based**: Modules tailored to specific classroom problems
- **Time-Bound**: 15-minute actionable sessions
- **Structured Output**: Sections with activities and implementation tips

### 3. Vernacular Translation
- **Multi-Language**: Support for 6+ Indian languages
- **Batch Translation**: Efficient translation of module sections
- **Fallback Handling**: Graceful degradation if translation fails

### 4. Offline-First PWA
- **Service Worker**: Caches API responses and static assets
- **Background Sync**: Queues requests when offline
- **Install Prompt**: Add to home screen capability

## ğŸ§ª Testing

```bash
# Backend tests
cd backend
pytest tests/ -v --cov

# Frontend tests
cd frontend
npm test
```

## ğŸ“Š Performance

- **Module Generation**: ~5-10 seconds (depends on LLM)
- **Translation**: ~2-3 seconds per section
- **Document Ingestion**: ~1 second per page
- **Vector Search**: <100ms for top-5 results

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md).

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team Laplace

**Innovation for Education Equity Hackathon**

- Team Member 1 - Full Stack Engineer
- Team Member 2 - ML Engineer
- Team Member 3 - Frontend Developer
- Team Member 4 - Backend Developer

## ğŸ™ Acknowledgments

- SCERT for training manual resources
- Ollama for local LLM deployment
- HuggingFace for open-source models
- Meta for NLLB translation models

## ğŸ“ Support

For questions or support, please open an issue on GitHub or contact us at [email@example.com](mailto:email@example.com).

---

**Built with â¤ï¸ for teachers transforming education**
